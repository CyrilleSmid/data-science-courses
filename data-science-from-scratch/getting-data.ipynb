{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://raw.githubusercontent.com/\"\n",
    "\"joelgrus/data/master/getting-data.html\")\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, features='html.parser')\n",
    "\n",
    "first_paragraph = soup.find('p')\n",
    "\n",
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_words = soup.p.text.split()\n",
    "\n",
    "first_paragraph_id = soup.p['id']\n",
    "all_paragraphs = soup.find_all('p')\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]\n",
    "\n",
    "important_paragraphs = soup('p', {'class' : 'important'})\n",
    "important_paragraphs2 = [p for p in soup('p')\n",
    "                         if 'important' in p.get('class', [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://carl.house.gov: {'/media/press-releases'}\n",
      "https://barrymoore.house.gov: {'/media/press-releases'}\n",
      "https://mikerogers.house.gov/: {'/news/documentquery.aspx?DocumentTypeID=27'}\n",
      "https://aderholt.house.gov/: {'/media-center/press-releases'}\n",
      "https://strong.house.gov: set()\n",
      "https://palmer.house.gov/: set()\n",
      "https://sewell.house.gov/: {'/press-releases'}\n",
      "https://peltola.house.gov: {'/news/documentquery.aspx?DocumentTypeID=27'}\n",
      "https://radewagen.house.gov: set()\n",
      "https://schweikert.house.gov/: set()\n",
      "https://crane.house.gov: set()\n",
      "https://rubengallego.house.gov/: set()\n"
     ]
    }
   ],
   "source": [
    "# Congressmen sites\n",
    "url = \"https://www.house.gov/representatives\"\n",
    "text = requests.get(url).text\n",
    "soup = BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "all_urls = [a['href']\n",
    "            for a in soup('a')\n",
    "            if a.has_attr('href')]\n",
    "\n",
    "regex = r\"^https?://.*\\.house\\.gov/?$\"\n",
    "good_urls = [url for url in all_urls if re.match(regex, url)]\n",
    "\n",
    "html = requests.get('https://jayapal.house.gov').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "press_releases: dict[str, set[str]] = {}\n",
    "\n",
    "for house_url in good_urls[:12]:\n",
    "    html = requests.get(house_url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    pr_links = {a['href'] for a in soup('a') if 'press releases'\n",
    "                                             in a.text.lower()}\n",
    "    print(f\"{house_url}: {pr_links}\")\n",
    "    press_releases[house_url] = pr_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://peltola.house.gov\n"
     ]
    }
   ],
   "source": [
    "def paragraph_mentions(text: str, keyword: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if a <p> inside the text mentions {keyword}\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text)\n",
    "    paragraphs = [p.get_text() for p in soup('p')]\n",
    "    return any(keyword.lower() in paragraph.lower()\n",
    "    for paragraph in paragraphs)\n",
    "\n",
    "for house_url, pr_links in press_releases.items():\n",
    "    for pr_link in pr_links:\n",
    "        url = f\"{house_url}/{pr_link}\"\n",
    "        text = requests.get(url).text\n",
    "    if paragraph_mentions(text, 'late'):\n",
    "        print(f\"{house_url}\")\n",
    "        break # done with this house_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GitHub API for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C#', 'Jupyter Notebook', 'R', 'C++', 'HTML']\n"
     ]
    }
   ],
   "source": [
    "github_user = 'CyrilleSmid'\n",
    "endpoint = f\"https://api.github.com/users/{github_user}/repos\"\n",
    "\n",
    "repos = json.loads(requests.get(endpoint).text)\n",
    "\n",
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_count = Counter(date.weekday() for date in dates)\n",
    "\n",
    "last_5_repositories = sorted(repos,\n",
    "                             key=lambda r: r[\"pushed_at\"],\n",
    "                             reverse=True)[:5]\n",
    "last_5_languages = [repo[\"language\"]\n",
    "                    for repo in last_5_repositories]\n",
    "print(last_5_languages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db30ed31b609ec6dba2973d4964665615fa673008b8f2439bf875c98f7bd432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
